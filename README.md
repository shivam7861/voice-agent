# Voice Agent Microservice

A modular, voice-enabled AI assistant built with **LiveKit Agents**, supporting **speech-to-text (STT), text-to-speech (TTS), LLM responses**, and noise cancellation. Designed with a **micro-architecture**, separating agents, sessions, and utilities for maintainability and scalability.  

---

## ğŸ“ Project Structure

  voice-agent/
  â”œâ”€â”€ src/
  â”‚ â”œâ”€â”€ agents/
  â”‚ â”‚ â”œâ”€â”€ init.py
  â”‚ â”‚ â””â”€â”€ voice_agent.py # Voice agent logic
  â”‚ â”œâ”€â”€ sessions/
  â”‚ â”‚ â”œâ”€â”€ init.py
  â”‚ â”‚ â””â”€â”€ entrypoint.py # Orchestrates agent sessions
  â”‚ â”œâ”€â”€ utils/
  â”‚ â”‚ â”œâ”€â”€ init.py
  â”‚ â”‚ â””â”€â”€ logger.py # Logger setup
  â”‚ â”‚ â””â”€â”€ config.py # Loads .env and API keys
  â”‚ â””â”€â”€ main.py # Entrypoint to run the agent
  â”œâ”€â”€ .env # Environment variables and API keys
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ README.md
  â””â”€â”€ .gitignore


---

## âš¡ Features

- **Voice interaction** via LiveKit Agents.
- **Speech-to-text (STT)** with AssemblyAI.
- **Text-to-speech (TTS)** with ElevenLabs.
- **Language understanding** using Groq LLM.
- **Voice activity detection (VAD)** with Silero.
- **Noise cancellation** via BVC plugin.
- Modular micro-architecture for easier maintenance.

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**
```bash
git clone <your_repo_url>
cd voice-agent-micro
---
2. **Create and activate a virtual environment**
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

3.  ** Install dependencies **
pip install -r requirements.txt

4.  ** Create .env file in the project root with your API keys: **
LIVEKIT_API_KEY=your_livekit_api_key
LIVEKIT_API_SECRET=your_livekit_api_secret
LIVEKIT_URL=wss://your-livekit-server-url
ASSEMBLYAI_API_KEY=your_assemblyai_key
ELEVENLABS_API_KEY=your_elevenlabs_key
GROQ_API_KEY=your_groq_key


5. ** Running the Voice Agent **
python -m src.main dev
dev enables development mode for LiveKit agents.
The agent will automatically connect to LiveKit, initialize STT, TTS, and LLM, and start interacting with users.

